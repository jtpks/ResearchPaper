>>> exec(open('test.py').read())
Model_id: ExtraTree Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [1 1 0 1 0 0 0 1 0]
Classification report: 
               precision    recall  f1-score   support

           0       1.00      0.83      0.91         6
           1       0.75      1.00      0.86         3

    accuracy                           0.89         9
   macro avg       0.88      0.92      0.88         9
weighted avg       0.92      0.89      0.89         9

=================================================================
Model_id: ExtraTree Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.81      0.93      0.87        14
           1       0.89      0.73      0.80        11

    accuracy                           0.84        25
   macro avg       0.85      0.83      0.83        25
weighted avg       0.85      0.84      0.84        25

=================================================================
Model_id: DecisionTree Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [0 1 0 1 1 0 0 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.83      0.83      0.83         6
           1       0.67      0.67      0.67         3

    accuracy                           0.78         9
   macro avg       0.75      0.75      0.75         9
weighted avg       0.78      0.78      0.78         9

=================================================================
Model_id: DecisionTree Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.72      0.93      0.81        14
           1       0.86      0.55      0.67        11

    accuracy                           0.76        25
   macro avg       0.79      0.74      0.74        25
weighted avg       0.78      0.76      0.75        25

=================================================================
Model_id: Logistic_L1 Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [0 0 0 1 0 0 1 0 1]
Classification report: 
               precision    recall  f1-score   support

           0       0.67      0.67      0.67         6
           1       0.33      0.33      0.33         3

    accuracy                           0.56         9
   macro avg       0.50      0.50      0.50         9
weighted avg       0.56      0.56      0.56         9

=================================================================
Model_id: Logistic_L1 Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.70      1.00      0.82        14
           1       1.00      0.45      0.62        11

    accuracy                           0.76        25
   macro avg       0.85      0.73      0.72        25
weighted avg       0.83      0.76      0.74        25

=================================================================
Model_id: Logistic_L2 Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [0 1 0 1 1 0 1 0 1]
Classification report: 
               precision    recall  f1-score   support

           0       0.75      0.50      0.60         6
           1       0.40      0.67      0.50         3

    accuracy                           0.56         9
   macro avg       0.57      0.58      0.55         9
weighted avg       0.63      0.56      0.57         9

=================================================================
Model_id: Logistic_L2 Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.70      1.00      0.82        14
           1       1.00      0.45      0.62        11

    accuracy                           0.76        25
   macro avg       0.85      0.73      0.72        25
weighted avg       0.83      0.76      0.74        25

=================================================================
Model_id: RandomForest Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [1 1 0 1 0 0 1 1 0]
Classification report: 
               precision    recall  f1-score   support

           0       1.00      0.67      0.80         6
           1       0.60      1.00      0.75         3

    accuracy                           0.78         9
   macro avg       0.80      0.83      0.77         9
weighted avg       0.87      0.78      0.78         9

=================================================================
Model_id: RandomForest Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [1 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.86      0.86      0.86        14
           1       0.82      0.82      0.82        11

    accuracy                           0.84        25
   macro avg       0.84      0.84      0.84        25
weighted avg       0.84      0.84      0.84        25

=================================================================
Model_id: mlp Data file : baseline.csv, Label : DND
Before sample  Counter({0: 16, 1: 11})
After sample  Counter({0: 16, 1: 11})
Complete Data Num Rows X Features:  27 8
Training Data Num Rows X Features:  18 8
Test Data Num Rows X Features:      9 8
y_test:  [0 1 0 1 0 0 0 1 0]
y_pred:  [0 1 0 1 1 0 0 0 1]
Classification report: 
               precision    recall  f1-score   support

           0       0.80      0.67      0.73         6
           1       0.50      0.67      0.57         3

    accuracy                           0.67         9
   macro avg       0.65      0.67      0.65         9
weighted avg       0.70      0.67      0.68         9

=================================================================
Model_id: mlp Data file : data1.csv, Label : DND
Before sample  Counter({0: 48, 1: 33})
After sample  Counter({0: 48, 1: 33})
Complete Data Num Rows X Features:  81 15
Training Data Num Rows X Features:  56 15
Test Data Num Rows X Features:      25 15
y_test:  [1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0]
y_pred:  [1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0]
Classification report: 
               precision    recall  f1-score   support

           0       0.75      0.86      0.80        14
           1       0.78      0.64      0.70        11

    accuracy                           0.76        25
   macro avg       0.76      0.75      0.75        25
weighted avg       0.76      0.76      0.76        25

=================================================================
